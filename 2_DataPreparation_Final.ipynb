{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb1ad62",
   "metadata": {},
   "source": [
    "## Data Processing and Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb1e48",
   "metadata": {},
   "source": [
    "### 1) Duplicate Removal\n",
    "Based on how the GDELT data was loaded, there is a potential for duplicate entries. These will be removed as part of the data processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5d623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aed5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the created GDELT dataset from the Data Load Notebook\n",
    "df_complete = pd.read_pickle('df_complete.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7044b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort dataframe by ADM1Code so that duplicate removal removes the less granular entry (e.g. in this case the country one)\n",
    "df_complete = df_complete.sort_values(\"ActionGeo_ADM1Code\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0235bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step is to remove duplicates by comparing all columns\n",
    "df_complete = df_complete.drop_duplicates(\n",
    "  subset = ['SQLDATE', 'MonthYear', 'Actor1Code', 'Actor2Code', 'EventCode', 'ActionGeo_ADM1Code'],\n",
    "  keep = 'last').reset_index(drop = True)\n",
    "len(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GDELT DATA has entries for a country on two levels (e.g. BN and BN00) which needs to merged into one for all countries \n",
    "#condition\n",
    "conditions = [df_complete['ActionGeo_ADM1Code']== 'BN',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'EK',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'GA',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'GH',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'GV',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'IV',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'LI',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'ML',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'MR',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'PU',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'SG',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'SL',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'TO',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'WI',\n",
    "             df_complete['ActionGeo_ADM1Code']== 'UV',]\n",
    "\n",
    "#values if condition are given\n",
    "values = ['BN00','EK00','GA00','GH00','GV00','IV00','LI00','ML00','MR00', 'PU00',\n",
    "        'SG00', 'SL00', 'TO00', 'WI00', 'UV00']\n",
    "\n",
    "#replace value in original column\n",
    "df_complete['ActionGeo_ADM1Code']=np.select(conditions, values, default = df_complete['ActionGeo_ADM1Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also remove duplicates where event is recorded on both ADM1 and country level \n",
    "df_complete = df_complete.drop_duplicates(\n",
    "  subset = ['SQLDATE', 'MonthYear', 'Actor1Code', 'Actor2Code', 'EventCode', 'GoldsteinScale', 'QuadClass', 'ActionGeo_CountryCode'],\n",
    "  keep = 'last').reset_index(drop = True)\n",
    "len(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ca179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove subdivisions that are not maintainted anymore (according to comparison to external ADM1 subdivisions)\n",
    "adm1_to_remove = ['LI15', 'LI16','LI17','LI18', 'MR13', 'SG16', 'SG17', 'SG18']\n",
    "df_complete.drop(df_complete[df_complete['ActionGeo_ADM1Code'].isin(adm1_to_remove)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedc688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the resulting dataframe has this many entries \n",
    "len(df_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85191092",
   "metadata": {},
   "source": [
    "### 2) Grouping and Extension\n",
    "In order to be able to forecast the number of conflicts by state, month and year, a grouping of the dataframe by the same dimensions needs to be performed.\n",
    "The decision was taken to work with the grouped dataset without the event code but there is also a potential to include the event code in future analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd76221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create grouped dataframes which sum up the number of events by the respective dimensions\n",
    "df_grouped_witheventcode  = df_complete.groupby(['MonthYear', 'EventCode', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code']).size().reset_index(name='number of conflicts')#\n",
    "df_grouped  = df_complete.groupby(['MonthYear', 'Year', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code']).size().reset_index(name='number of conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70877e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c54f01",
   "metadata": {},
   "source": [
    "GDELT data only contains data on conflicts that happened. Therefore, data needs to be added for the intersection of states, months and years for which 0 conflicts have been recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead557af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of the complete MonthYears and States have been created \n",
    "all_available_states = list(pd.read_excel(\"CompleteStatesAndMonthYears.xlsx\", sheet_name = \"States\")['ADM1'])\n",
    "all_available_yearmonths = list(pd.read_excel(\"CompleteStatesAndMonthYears.xlsx\", sheet_name = \"MonthYear\")['MonthYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844daec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an empty dataframe is created in which all missing intersections will be written with 0 conflicts\n",
    "missing_intersection = pd.DataFrame(columns = ['MonthYear', 'Year', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code',\n",
    "       'number of conflicts'])\n",
    "\n",
    "df_filtered = pd.DataFrame()\n",
    "for state in all_available_states:\n",
    "    for date in all_available_yearmonths:\n",
    "        del df_filtered\n",
    "        df_filtered = df_grouped[(df_grouped['ActionGeo_ADM1Code']==state)\n",
    "                       & (df_grouped['MonthYear']==date)]\n",
    "        if len(df_filtered) == 0: \n",
    "            additional_entries = []\n",
    "            additional_entries = [date, str(date)[0:4], [state[i:i + 2] for i in range(0, len(state), 2)][0], state, 0]\n",
    "            missing_intersection.loc[len(missing_intersection)] = additional_entries\n",
    "        else: \n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a50ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_grouped), len(missing_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat grouped dataframe with missing intersection to receive complete dataset\n",
    "df_complete2 = pd.concat([df_grouped, missing_intersection], axis=0)\n",
    "len(df_complete2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dataset for immediate processing\n",
    "df_complete2.to_pickle(path = \"df_complete2_extended.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a15152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset for immediate processing\n",
    "df_complete2 = pd.read_pickle(\"df_complete2_extended.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2338c4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102444"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the length of the dataset\n",
    "len(df_complete2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed44833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all entries prior to 1982 as these are irrelevant for further processing\n",
    "df_complete2 = df_complete2[df_complete2[\"MonthYear\"] != 192001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81f1ea",
   "metadata": {},
   "source": [
    "### 3) Additional Predictors\n",
    "Now that we have the raw GDELT data in the format of number of conflicts per month and state, we join additional predictors, the HDI and WBI in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbc649",
   "metadata": {},
   "source": [
    "**HDI Data**\n",
    "\n",
    "The nomenclature of the HDI dataset is different from the GDELT data in regards to the states and years, so in a first step we write down the iso_codes for the relevant countries and filter the dataset accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10983582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define all relevant countries \n",
    "relevant_countries = [\"BEN\", \"GNQ\", \"GMB\", \"GHA\", \"GIN\", \"CIV\", \"LBR\", \"MLI\", \"MRT\", \"GNB\", \"SEN\", \"SLE\", \"TGO\", \"BFA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973dcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the hdi data for the respective countries\n",
    "country_hdi_data=pd.read_excel('SHDI-SGDI-Total 5.0 (1).xlsx', sheet_name=0)\n",
    "country_hdi_data=country_hdi_data[country_hdi_data['iso_code'].isin(relevant_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4db5724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of the hdi dataset\n",
    "len(country_hdi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aceeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as states and countries have a different nomenclature, a manual match between the states has been performed and recorded\n",
    "#in the excel file below which gets read into a dataframe\n",
    "matched_states = pd.read_excel('states_markup.xlsx', sheet_name = \"Final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38c41ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm1</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>iso_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BN00</td>\n",
       "      <td>BN</td>\n",
       "      <td>Total</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BN01</td>\n",
       "      <td>BN</td>\n",
       "      <td>Atacora (incl Donga)</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BN02</td>\n",
       "      <td>BN</td>\n",
       "      <td>Atlantique (incl Littoral (Cotonou))</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BN03</td>\n",
       "      <td>BN</td>\n",
       "      <td>Borgou (incl Alibori)</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BN04</td>\n",
       "      <td>BN</td>\n",
       "      <td>Mono (incl Couffo)</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adm1 country                                region iso_code\n",
       "0  BN00      BN                                 Total      BEN\n",
       "1  BN01      BN                  Atacora (incl Donga)      BEN\n",
       "2  BN02      BN  Atlantique (incl Littoral (Cotonou))      BEN\n",
       "3  BN03      BN                 Borgou (incl Alibori)      BEN\n",
       "4  BN04      BN                    Mono (incl Couffo)      BEN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e978e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for later processing, the country and adm1 description of the GDELT dataset is added to the HDI data \n",
    "#NOTE: as there is no 1:1 match between the states, the length of the dataset increases \n",
    "new_hdi = country_hdi_data.merge(matched_states, on=['iso_code', 'region'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2257ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_hdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5208c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_code                           object\n",
       "country_x                          object\n",
       "year                                int64\n",
       "level                              object\n",
       "region                             object\n",
       "gender development index (GDI)     object\n",
       "human development index (HDI)     float64\n",
       "health index                      float64\n",
       "income index                      float64\n",
       "educational index                 float64\n",
       "expected years of schooling       float64\n",
       "mean years of scholing            float64\n",
       "life expectancy                   float64\n",
       "GNI per capita (000'000)          float64\n",
       "population (000'000)               object\n",
       "adm1                               object\n",
       "country_y                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next, we drop some columns and rename the kept ones\n",
    "#NOTE: some of the categorical columns are erased + indicators which are separated in male and female again\n",
    "new_hdi.drop(columns = ['GDLCODE', 'continent',\n",
    "                               'shdif', 'shdim','healthindexf', 'healthindexm',\n",
    "                               'incindexf', 'incindexm','edindexf', 'edindexm',\n",
    "                               'eschf', 'eschm','mschf', 'mschm', 'lifexpf',\n",
    "                               'lifexpm', 'gnic', 'gnicf', 'gnicm','lgnicf', 'lgnicm',\n",
    "                               'mfsel'], inplace = True)\n",
    "\n",
    "new_hdi.rename(columns={\"pop\": \"population (000'000)\", \"lgnic\": \"GNI per capita (000'000)\", \n",
    "                                      \"msch\": \"mean years of scholing\", \"esch\": \"expected years of schooling\", \n",
    "                                      \"lifexp\": \"life expectancy\", \"incindex\": \"income index\", \n",
    "                                      \"edindex\": \"educational index\", \"healthindex\": \"health index\", \n",
    "                                      \"shdi\": \"human development index (HDI)\", \"sgdi\": \"gender development index (GDI)\"},\n",
    "                             inplace = True)\n",
    "\n",
    "new_hdi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc10bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_code                           object\n",
       "country_x                          object\n",
       "year                                int64\n",
       "level                              object\n",
       "region                             object\n",
       "gender development index (GDI)    float64\n",
       "human development index (HDI)     float64\n",
       "health index                      float64\n",
       "income index                      float64\n",
       "educational index                 float64\n",
       "expected years of schooling       float64\n",
       "mean years of scholing            float64\n",
       "life expectancy                   float64\n",
       "GNI per capita (000'000)          float64\n",
       "population (000'000)               object\n",
       "adm1                               object\n",
       "country_y                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gender development index is in an incorrect type format, so we update it \n",
    "new_hdi['gender development index (GDI)'] = pd.to_numeric(new_hdi['gender development index (GDI)'], errors='coerce')\n",
    "new_hdi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17fac813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990 2019\n"
     ]
    }
   ],
   "source": [
    "#we check the minimum and maximum year of the HDI dataset which reveals that the time span covered is shorter compared\n",
    "#to the GDELT dataset\n",
    "print(min(new_hdi['year']), max(new_hdi['year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198fbc4",
   "metadata": {},
   "source": [
    "For the below special cases, no direct mapping of states was possible. Instead, an average of multiple states is required or th national total value is kept in case no match at all was identifiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78bfcc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>gender development index (GDI)</th>\n",
       "      <th>human development index (HDI)</th>\n",
       "      <th>health index</th>\n",
       "      <th>income index</th>\n",
       "      <th>educational index</th>\n",
       "      <th>expected years of schooling</th>\n",
       "      <th>mean years of scholing</th>\n",
       "      <th>life expectancy</th>\n",
       "      <th>GNI per capita (000'000)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.47650</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.33125</td>\n",
       "      <td>6.5915</td>\n",
       "      <td>4.4495</td>\n",
       "      <td>53.27350</td>\n",
       "      <td>8.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48575</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.33575</td>\n",
       "      <td>6.7565</td>\n",
       "      <td>4.4495</td>\n",
       "      <td>53.57325</td>\n",
       "      <td>9.0145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  gender development index (GDI)  human development index (HDI)  \\\n",
       "0  2000                             NaN                        0.47650   \n",
       "1  2001                             NaN                        0.48575   \n",
       "\n",
       "   health index  income index  educational index  expected years of schooling  \\\n",
       "0        0.5120         0.643            0.33125                       6.5915   \n",
       "1        0.5165         0.666            0.33575                       6.7565   \n",
       "\n",
       "   mean years of scholing  life expectancy  GNI per capita (000'000)  \n",
       "0                  4.4495         53.27350                    8.8600  \n",
       "1                  4.4495         53.57325                    9.0145  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special case for EK02 \n",
    "ek = new_hdi[new_hdi['iso_code'] == \"GNQ\"]\n",
    "ek = ek[(ek[\"region\"] != \"Annobon, Bioko\") & (ek['level'] == \"Subnat\")]\n",
    "ek02 = ek.groupby(['year']).mean().reset_index()\n",
    "ek02.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0dc1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ek02['level'] = \"Subnat\"\n",
    "ek02['iso_code'] = \"GNQ\"\n",
    "ek02['adm1'] = \"EK02\"\n",
    "ek02['country_y'] = \"EK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e337d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 6995)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ek02), len(new_hdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ddc703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the special case EK02 to the HDI dataset\n",
    "new_hdi = pd.concat([new_hdi, ek02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbdb3bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 14), (7015, 17))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ek02.shape, new_hdi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ac9e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case for SG02 \n",
    "sg = new_hdi[new_hdi['iso_code'] == \"SEN\"]\n",
    "sg02_regions = [\"Ziguinchor\", \"Kolda\"]\n",
    "sg02 = sg[(sg[\"region\"].isin(sg02_regions)) & (sg['level'] == \"Subnat\")]\n",
    "sg02 = sg02.groupby(['year']).mean().reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc732eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg02['level'] = \"Subnat\"\n",
    "sg02['iso_code'] = \"SEN\"\n",
    "sg02['adm1'] = \"SG02\"\n",
    "sg02['country_y'] = \"SG\"\n",
    "#add the special case SG02 to the HDI dataset\n",
    "new_hdi = pd.concat([new_hdi, sg02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce2fc20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7045)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sg02), len(new_hdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6f80fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case for SG15\n",
    "sg15 = sg[sg['level'] == \"Subnat\"]\n",
    "sg15 = sg15.groupby(['year']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32219d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg15['level'] = \"Subnat\"\n",
    "sg15['iso_code'] = \"SEN\"\n",
    "sg15['adm1'] = \"SG15\"\n",
    "sg15['country_y'] = \"SG\"\n",
    "#add the special case SG15 to the HDI dataset\n",
    "new_hdi = pd.concat([new_hdi, sg15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cc8547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7075)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sg15), len(new_hdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41863c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete subnational for Guinea (GV), Cote D'Ivoire (IV), Sierra Leone (SL), Burkina Faso (UV). total values will be used\n",
    "# as no mapping on state level was possible\n",
    "new_hdi.drop(new_hdi[(new_hdi['iso_code'] == \"GIN\") & (new_hdi['level'] == \"Subnat\")].index, inplace = True)\n",
    "new_hdi.drop(new_hdi[(new_hdi['iso_code'] == \"SLE\") & (new_hdi['level'] == \"Subnat\")].index, inplace = True)\n",
    "new_hdi.drop(new_hdi[(new_hdi['iso_code'] == \"CIV\") & (new_hdi['level'] == \"Subnat\")].index, inplace = True)\n",
    "new_hdi.drop(new_hdi[(new_hdi['iso_code'] == \"BFA\") & (new_hdi['level'] == \"Subnat\")].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e248b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5855, 17), (102412, 5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hdi.shape, df_complete2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc899505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that year type is correct for the merge\n",
    "df_complete2[\"Year\"] = df_complete2[\"Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ce53d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>Year</th>\n",
       "      <th>ActionGeo_CountryCode</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>number of conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>198201</td>\n",
       "      <td>1982</td>\n",
       "      <td>GH</td>\n",
       "      <td>GH00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>198201</td>\n",
       "      <td>1982</td>\n",
       "      <td>GH</td>\n",
       "      <td>GH01</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>198201</td>\n",
       "      <td>1982</td>\n",
       "      <td>GH</td>\n",
       "      <td>GH02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>198201</td>\n",
       "      <td>1982</td>\n",
       "      <td>LI</td>\n",
       "      <td>LI00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>198201</td>\n",
       "      <td>1982</td>\n",
       "      <td>ML</td>\n",
       "      <td>ML00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81773</th>\n",
       "      <td>201807</td>\n",
       "      <td>2018</td>\n",
       "      <td>UV</td>\n",
       "      <td>UV91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81774</th>\n",
       "      <td>201907</td>\n",
       "      <td>2019</td>\n",
       "      <td>UV</td>\n",
       "      <td>UV91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81775</th>\n",
       "      <td>202007</td>\n",
       "      <td>2020</td>\n",
       "      <td>UV</td>\n",
       "      <td>UV91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81776</th>\n",
       "      <td>202107</td>\n",
       "      <td>2021</td>\n",
       "      <td>UV</td>\n",
       "      <td>UV91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81777</th>\n",
       "      <td>202207</td>\n",
       "      <td>2022</td>\n",
       "      <td>UV</td>\n",
       "      <td>UV91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102412 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonthYear  Year ActionGeo_CountryCode ActionGeo_ADM1Code  \\\n",
       "32        198201  1982                    GH               GH00   \n",
       "33        198201  1982                    GH               GH01   \n",
       "34        198201  1982                    GH               GH02   \n",
       "35        198201  1982                    LI               LI00   \n",
       "36        198201  1982                    ML               ML00   \n",
       "...          ...   ...                   ...                ...   \n",
       "81773     201807  2018                    UV               UV91   \n",
       "81774     201907  2019                    UV               UV91   \n",
       "81775     202007  2020                    UV               UV91   \n",
       "81776     202107  2021                    UV               UV91   \n",
       "81777     202207  2022                    UV               UV91   \n",
       "\n",
       "       number of conflicts  \n",
       "32                      14  \n",
       "33                      23  \n",
       "34                       5  \n",
       "35                       2  \n",
       "36                       2  \n",
       "...                    ...  \n",
       "81773                    0  \n",
       "81774                    0  \n",
       "81775                    0  \n",
       "81776                    0  \n",
       "81777                    0  \n",
       "\n",
       "[102412 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37debb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the HDI data to the complete dataset by performing a left join on year and adm1code\n",
    "test_df = pd.merge(df_complete2, new_hdi,  how='left', left_on=[\"Year\", \"ActionGeo_ADM1Code\"], right_on = [\"year\", \"adm1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2724827",
   "metadata": {},
   "source": [
    "**World Bank Indicators**\n",
    "\n",
    "World Development Indicators (WDI) is the primary World Bank collection of development indicators, compiled from officially recognized international sources, it forms a compilation of international statistics on global development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b678adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the WBI data for each country and merging the data in the correct format into a dataframe\n",
    "available_files = ['API_BEN_DS2_en_excel_v2_4363258.xls', 'API_BFA_DS2_en_excel_v2_4339316.xls',\n",
    "'API_CIV_DS2_en_excel_v2_4324130.xls', 'API_GHA_DS2_en_excel_v2_4320378.xls',\n",
    "'API_GIN_DS2_en_excel_v2_4364647.xls', 'API_GMB_DS2_en_excel_v2_4331096.xls',\n",
    "'API_GNB_DS2_en_excel_v2_4346479.xls', 'API_GNQ_DS2_en_excel_v2_4346476.xls',\n",
    "'API_LBR_DS2_en_excel_v2_4346179.xls', 'API_MLI_DS2_en_excel_v2_4318686.xls',\n",
    "'API_MRT_DS2_en_excel_v2_4322231.xls', 'API_SEN_DS2_en_excel_v2_4347087.xls',\n",
    "'API_SLE_DS2_en_excel_v2_4346481.xls', 'API_TGO_DS2_en_excel_v2_4346620.xls']\n",
    "\n",
    "#now only using a subset of the predictors. potential to extend this list\n",
    "useful_predictors = [\"SL.UEM.TOTL.MA.ZS\", \"SL.UEM.TOTL.ZS\",\"SL.UEM.TOTL.FE.ZS\",\"SL.EMP.TOTL.SP.ZS\",\"EG.CFT.ACCS.ZS\",\n",
    "                        \"EG.ELC.ACCS.ZS\",\"FP.CPI.TOTL\",\"NY.GDP.MKTP.KD\",\"NY.GDP.PCAP.KD\",\"NY.GDP.PETR.RT.ZS\",\n",
    "                        \"SM.POP.REFG\",\"SP.RUR.TOTL.ZS\"]\n",
    "\n",
    "list1 = list(range(1982, 2022))\n",
    "list2 = list(map(str, list1))\n",
    "\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "for files in available_files: \n",
    "    country_wbi =pd.read_excel(files, skiprows = 3)\n",
    "    \n",
    "    country_wbi.drop(country_wbi.iloc[:, 4:26],axis = 1, inplace = True)\n",
    "    country_wbi = country_wbi[country_wbi['Indicator Code'].isin(useful_predictors)]\n",
    "\n",
    "    country_wbi.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    country_name = country_wbi['Country Code'][0]\n",
    "    country_wbi.drop(columns = ['Country Name', 'Country Code', 'Indicator Code'], inplace = True)\n",
    "\n",
    "    country_wbi_new = pd.melt(country_wbi, id_vars='Indicator Name', value_vars= list2,\n",
    "                              var_name='year', value_name='amount')\n",
    "\n",
    "    country_wbi_new['Country Code'] = country_name\n",
    "    \n",
    "    df_temp = pd.concat([df_temp, country_wbi_new])\n",
    "    \n",
    "    country_wbi = pd.DataFrame()\n",
    "    countri_wbi_new = pd.DataFrame()\n",
    "    \n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "\n",
    "df_grouped = df_temp.groupby([\"Country Code\", \"Indicator Name\"]).mean()\n",
    "df_grouped.reset_index(inplace = True)\n",
    "\n",
    "for index, row in df_temp.iterrows(): \n",
    "    if pd.isna(row['amount']) == True: \n",
    "        df_temp.at[index, 'amount'] = df_grouped[(df_grouped['Country Code'] == row['Country Code']) & (df_grouped['Indicator Name'] == row['Indicator Name'])]['amount']\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2e74c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Access to clean fuels and technologies for cooking (% of population)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Consumer price index (2010 = 100)</th>\n",
       "      <th>Employment to population ratio, 15+, total (%) (modeled ILO estimate)</th>\n",
       "      <th>GDP (constant 2015 US$)</th>\n",
       "      <th>GDP per capita (constant 2015 US$)</th>\n",
       "      <th>Oil rents (% of GDP)</th>\n",
       "      <th>Refugee population by country or territory of asylum</th>\n",
       "      <th>Rural population (% of total population)</th>\n",
       "      <th>Unemployment, female (% of female labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, male (% of male labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, total (% of total labor force) (modeled ILO estimate)</th>\n",
       "      <th>Country Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>67.273226</td>\n",
       "      <td>4.941037e+08</td>\n",
       "      <td>609.702019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.53125</td>\n",
       "      <td>79.987</td>\n",
       "      <td>7.038645</td>\n",
       "      <td>5.415355</td>\n",
       "      <td>6.180968</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>67.273226</td>\n",
       "      <td>4.773127e+08</td>\n",
       "      <td>574.928657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.53125</td>\n",
       "      <td>78.806</td>\n",
       "      <td>7.038645</td>\n",
       "      <td>5.415355</td>\n",
       "      <td>6.180968</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>67.273226</td>\n",
       "      <td>5.207921e+08</td>\n",
       "      <td>611.778255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.53125</td>\n",
       "      <td>77.574</td>\n",
       "      <td>7.038645</td>\n",
       "      <td>5.415355</td>\n",
       "      <td>6.180968</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>67.273226</td>\n",
       "      <td>5.424909e+08</td>\n",
       "      <td>622.006338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.53125</td>\n",
       "      <td>76.296</td>\n",
       "      <td>7.038645</td>\n",
       "      <td>5.415355</td>\n",
       "      <td>6.180968</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>67.273226</td>\n",
       "      <td>5.381844e+08</td>\n",
       "      <td>602.987421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8800.53125</td>\n",
       "      <td>74.966</td>\n",
       "      <td>7.038645</td>\n",
       "      <td>5.415355</td>\n",
       "      <td>6.180968</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>34.779999</td>\n",
       "      <td>110.229263</td>\n",
       "      <td>64.035004</td>\n",
       "      <td>1.460765e+10</td>\n",
       "      <td>789.072631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17036.00000</td>\n",
       "      <td>58.428</td>\n",
       "      <td>8.386000</td>\n",
       "      <td>6.687000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>50.900002</td>\n",
       "      <td>110.559451</td>\n",
       "      <td>63.983002</td>\n",
       "      <td>1.530100e+10</td>\n",
       "      <td>802.033621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26538.00000</td>\n",
       "      <td>57.644</td>\n",
       "      <td>8.403000</td>\n",
       "      <td>6.705000</td>\n",
       "      <td>7.428000</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>47.836277</td>\n",
       "      <td>108.726080</td>\n",
       "      <td>63.918999</td>\n",
       "      <td>1.602874e+10</td>\n",
       "      <td>815.379101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26672.00000</td>\n",
       "      <td>56.864</td>\n",
       "      <td>8.414000</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>7.442000</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>50.561417</td>\n",
       "      <td>109.202397</td>\n",
       "      <td>63.139000</td>\n",
       "      <td>1.583071e+10</td>\n",
       "      <td>781.731457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47380.00000</td>\n",
       "      <td>56.091</td>\n",
       "      <td>8.685000</td>\n",
       "      <td>6.962000</td>\n",
       "      <td>7.696000</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.861905</td>\n",
       "      <td>24.045783</td>\n",
       "      <td>113.489249</td>\n",
       "      <td>63.266998</td>\n",
       "      <td>1.631670e+10</td>\n",
       "      <td>782.360580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49975.00000</td>\n",
       "      <td>55.323</td>\n",
       "      <td>8.847000</td>\n",
       "      <td>6.887000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Indicator Name  Access to clean fuels and technologies for cooking (% of population)  \\\n",
       "year                                                                                   \n",
       "1982                                                     1.152381                      \n",
       "1983                                                     1.152381                      \n",
       "1984                                                     1.152381                      \n",
       "1985                                                     1.152381                      \n",
       "1986                                                     1.152381                      \n",
       "...                                                           ...                      \n",
       "2017                                                     0.900000                      \n",
       "2018                                                     0.900000                      \n",
       "2019                                                     0.900000                      \n",
       "2020                                                     0.900000                      \n",
       "2021                                                     0.861905                      \n",
       "\n",
       "Indicator Name  Access to electricity (% of population)  \\\n",
       "year                                                      \n",
       "1982                                          14.680897   \n",
       "1983                                          14.680897   \n",
       "1984                                          14.680897   \n",
       "1985                                          14.680897   \n",
       "1986                                          14.680897   \n",
       "...                                                 ...   \n",
       "2017                                          34.779999   \n",
       "2018                                          50.900002   \n",
       "2019                                          47.836277   \n",
       "2020                                          50.561417   \n",
       "2021                                          24.045783   \n",
       "\n",
       "Indicator Name  Consumer price index (2010 = 100)  \\\n",
       "year                                                \n",
       "1982                                    69.858202   \n",
       "1983                                    69.858202   \n",
       "1984                                    69.858202   \n",
       "1985                                    69.858202   \n",
       "1986                                    69.858202   \n",
       "...                                           ...   \n",
       "2017                                   110.229263   \n",
       "2018                                   110.559451   \n",
       "2019                                   108.726080   \n",
       "2020                                   109.202397   \n",
       "2021                                   113.489249   \n",
       "\n",
       "Indicator Name  Employment to population ratio, 15+, total (%) (modeled ILO estimate)  \\\n",
       "year                                                                                    \n",
       "1982                                                    67.273226                       \n",
       "1983                                                    67.273226                       \n",
       "1984                                                    67.273226                       \n",
       "1985                                                    67.273226                       \n",
       "1986                                                    67.273226                       \n",
       "...                                                           ...                       \n",
       "2017                                                    64.035004                       \n",
       "2018                                                    63.983002                       \n",
       "2019                                                    63.918999                       \n",
       "2020                                                    63.139000                       \n",
       "2021                                                    63.266998                       \n",
       "\n",
       "Indicator Name  GDP (constant 2015 US$)  GDP per capita (constant 2015 US$)  \\\n",
       "year                                                                          \n",
       "1982                       4.941037e+08                          609.702019   \n",
       "1983                       4.773127e+08                          574.928657   \n",
       "1984                       5.207921e+08                          611.778255   \n",
       "1985                       5.424909e+08                          622.006338   \n",
       "1986                       5.381844e+08                          602.987421   \n",
       "...                                 ...                                 ...   \n",
       "2017                       1.460765e+10                          789.072631   \n",
       "2018                       1.530100e+10                          802.033621   \n",
       "2019                       1.602874e+10                          815.379101   \n",
       "2020                       1.583071e+10                          781.731457   \n",
       "2021                       1.631670e+10                          782.360580   \n",
       "\n",
       "Indicator Name  Oil rents (% of GDP)  \\\n",
       "year                                   \n",
       "1982                             0.0   \n",
       "1983                             0.0   \n",
       "1984                             0.0   \n",
       "1985                             0.0   \n",
       "1986                             0.0   \n",
       "...                              ...   \n",
       "2017                             0.0   \n",
       "2018                             0.0   \n",
       "2019                             0.0   \n",
       "2020                             0.0   \n",
       "2021                             0.0   \n",
       "\n",
       "Indicator Name  Refugee population by country or territory of asylum  \\\n",
       "year                                                                   \n",
       "1982                                                   8800.53125      \n",
       "1983                                                   8800.53125      \n",
       "1984                                                   8800.53125      \n",
       "1985                                                   8800.53125      \n",
       "1986                                                   8800.53125      \n",
       "...                                                           ...      \n",
       "2017                                                  17036.00000      \n",
       "2018                                                  26538.00000      \n",
       "2019                                                  26672.00000      \n",
       "2020                                                  47380.00000      \n",
       "2021                                                  49975.00000      \n",
       "\n",
       "Indicator Name  Rural population (% of total population)  \\\n",
       "year                                                       \n",
       "1982                                              79.987   \n",
       "1983                                              78.806   \n",
       "1984                                              77.574   \n",
       "1985                                              76.296   \n",
       "1986                                              74.966   \n",
       "...                                                  ...   \n",
       "2017                                              58.428   \n",
       "2018                                              57.644   \n",
       "2019                                              56.864   \n",
       "2020                                              56.091   \n",
       "2021                                              55.323   \n",
       "\n",
       "Indicator Name  Unemployment, female (% of female labor force) (modeled ILO estimate)  \\\n",
       "year                                                                                    \n",
       "1982                                                     7.038645                       \n",
       "1983                                                     7.038645                       \n",
       "1984                                                     7.038645                       \n",
       "1985                                                     7.038645                       \n",
       "1986                                                     7.038645                       \n",
       "...                                                           ...                       \n",
       "2017                                                     8.386000                       \n",
       "2018                                                     8.403000                       \n",
       "2019                                                     8.414000                       \n",
       "2020                                                     8.685000                       \n",
       "2021                                                     8.847000                       \n",
       "\n",
       "Indicator Name  Unemployment, male (% of male labor force) (modeled ILO estimate)  \\\n",
       "year                                                                                \n",
       "1982                                                     5.415355                   \n",
       "1983                                                     5.415355                   \n",
       "1984                                                     5.415355                   \n",
       "1985                                                     5.415355                   \n",
       "1986                                                     5.415355                   \n",
       "...                                                           ...                   \n",
       "2017                                                     6.687000                   \n",
       "2018                                                     6.705000                   \n",
       "2019                                                     6.720000                   \n",
       "2020                                                     6.962000                   \n",
       "2021                                                     6.887000                   \n",
       "\n",
       "Indicator Name  Unemployment, total (% of total labor force) (modeled ILO estimate)  \\\n",
       "year                                                                                  \n",
       "1982                                                     6.180968                     \n",
       "1983                                                     6.180968                     \n",
       "1984                                                     6.180968                     \n",
       "1985                                                     6.180968                     \n",
       "1986                                                     6.180968                     \n",
       "...                                                           ...                     \n",
       "2017                                                     7.410000                     \n",
       "2018                                                     7.428000                     \n",
       "2019                                                     7.442000                     \n",
       "2020                                                     7.696000                     \n",
       "2021                                                     7.720000                     \n",
       "\n",
       "Indicator Name Country Code  \n",
       "year                         \n",
       "1982                    GNB  \n",
       "1983                    GNB  \n",
       "1984                    GNB  \n",
       "1985                    GNB  \n",
       "1986                    GNB  \n",
       "...                     ...  \n",
       "2017                    MLI  \n",
       "2018                    MLI  \n",
       "2019                    MLI  \n",
       "2020                    MLI  \n",
       "2021                    MLI  \n",
       "\n",
       "[560 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = list(set(df_temp['Country Code']))\n",
    "df_wbi_final = pd.DataFrame()\n",
    "for country in countries: \n",
    "    df_filtered = df_temp[df_temp['Country Code'] == country]\n",
    "    df_wbi_temp2 = pd.pivot(df_filtered, index = 'year', columns = 'Indicator Name', values = 'amount')\n",
    "    \n",
    "    df_wbi_temp2['Country Code'] = country\n",
    "    df_wbi_final = pd.concat([df_wbi_final, df_wbi_temp2])   \n",
    "    \n",
    "    df_wbi_temp2 = pd.DataFrame()\n",
    "    df_filtered = pd.DataFrame()\n",
    "    \n",
    "df_wbi_final.reset_index()\n",
    "df_wbi_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a55ce969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to excel for testing\n",
    "df_wbi_final.to_excel(\"df_wbi_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9fd0484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Indicator Name</th>\n",
       "      <th>year</th>\n",
       "      <th>Access to clean fuels and technologies for cooking (% of population)</th>\n",
       "      <th>Access to electricity (% of population)</th>\n",
       "      <th>Consumer price index (2010 = 100)</th>\n",
       "      <th>Employment to population ratio, 15+, total (%) (modeled ILO estimate)</th>\n",
       "      <th>GDP (constant 2015 US$)</th>\n",
       "      <th>GDP per capita (constant 2015 US$)</th>\n",
       "      <th>Oil rents (% of GDP)</th>\n",
       "      <th>Refugee population by country or territory of asylum</th>\n",
       "      <th>Rural population (% of total population)</th>\n",
       "      <th>Unemployment, female (% of female labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, male (% of male labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, total (% of total labor force) (modeled ILO estimate)</th>\n",
       "      <th>Country Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021</td>\n",
       "      <td>1.152381</td>\n",
       "      <td>14.680897</td>\n",
       "      <td>69.858202</td>\n",
       "      <td>66.037003</td>\n",
       "      <td>1.265073e+09</td>\n",
       "      <td>627.675020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>55.383</td>\n",
       "      <td>7.694</td>\n",
       "      <td>5.932</td>\n",
       "      <td>6.759</td>\n",
       "      <td>GNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>12.451786</td>\n",
       "      <td>104.172660</td>\n",
       "      <td>71.669998</td>\n",
       "      <td>3.240179e+09</td>\n",
       "      <td>625.492033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8169.0</td>\n",
       "      <td>47.427</td>\n",
       "      <td>3.365</td>\n",
       "      <td>4.739</td>\n",
       "      <td>4.095</td>\n",
       "      <td>LBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2021</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>29.255348</td>\n",
       "      <td>116.044206</td>\n",
       "      <td>69.830002</td>\n",
       "      <td>1.569745e+10</td>\n",
       "      <td>1260.734609</td>\n",
       "      <td>0.530840</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>51.028</td>\n",
       "      <td>1.860</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.574</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2021</td>\n",
       "      <td>32.359524</td>\n",
       "      <td>47.738296</td>\n",
       "      <td>80.244155</td>\n",
       "      <td>42.876999</td>\n",
       "      <td>2.424600e+10</td>\n",
       "      <td>1409.953856</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>14479.0</td>\n",
       "      <td>51.400</td>\n",
       "      <td>3.997</td>\n",
       "      <td>3.544</td>\n",
       "      <td>3.723</td>\n",
       "      <td>SEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2021</td>\n",
       "      <td>22.297619</td>\n",
       "      <td>65.893630</td>\n",
       "      <td>71.802009</td>\n",
       "      <td>49.854000</td>\n",
       "      <td>9.534008e+09</td>\n",
       "      <td>6575.672189</td>\n",
       "      <td>21.880515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.439</td>\n",
       "      <td>10.609</td>\n",
       "      <td>8.419</td>\n",
       "      <td>9.245</td>\n",
       "      <td>GNQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2021</td>\n",
       "      <td>20.733333</td>\n",
       "      <td>55.635514</td>\n",
       "      <td>118.991106</td>\n",
       "      <td>53.574001</td>\n",
       "      <td>6.531937e+10</td>\n",
       "      <td>2414.440339</td>\n",
       "      <td>0.967656</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>47.820</td>\n",
       "      <td>4.144</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.468</td>\n",
       "      <td>CIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.411905</td>\n",
       "      <td>15.661907</td>\n",
       "      <td>297.185330</td>\n",
       "      <td>53.019001</td>\n",
       "      <td>5.128555e+09</td>\n",
       "      <td>629.939682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>345.0</td>\n",
       "      <td>56.628</td>\n",
       "      <td>4.650</td>\n",
       "      <td>6.023</td>\n",
       "      <td>5.333</td>\n",
       "      <td>SLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2021</td>\n",
       "      <td>4.130952</td>\n",
       "      <td>33.871515</td>\n",
       "      <td>74.763121</td>\n",
       "      <td>55.111000</td>\n",
       "      <td>5.460540e+09</td>\n",
       "      <td>644.065112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10683.0</td>\n",
       "      <td>56.642</td>\n",
       "      <td>3.114</td>\n",
       "      <td>4.852</td>\n",
       "      <td>4.004</td>\n",
       "      <td>TGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2021</td>\n",
       "      <td>2.709524</td>\n",
       "      <td>39.431974</td>\n",
       "      <td>196.461489</td>\n",
       "      <td>50.965000</td>\n",
       "      <td>1.768338e+09</td>\n",
       "      <td>711.050403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4418.0</td>\n",
       "      <td>36.778</td>\n",
       "      <td>14.820</td>\n",
       "      <td>8.430</td>\n",
       "      <td>11.212</td>\n",
       "      <td>GMB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2021</td>\n",
       "      <td>39.757143</td>\n",
       "      <td>32.948903</td>\n",
       "      <td>71.657125</td>\n",
       "      <td>39.612999</td>\n",
       "      <td>7.372519e+09</td>\n",
       "      <td>1543.947556</td>\n",
       "      <td>1.033768</td>\n",
       "      <td>101942.0</td>\n",
       "      <td>43.867</td>\n",
       "      <td>13.004</td>\n",
       "      <td>10.780</td>\n",
       "      <td>11.463</td>\n",
       "      <td>MRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>27.649023</td>\n",
       "      <td>327.463207</td>\n",
       "      <td>58.181000</td>\n",
       "      <td>1.302990e+10</td>\n",
       "      <td>965.375522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5741.0</td>\n",
       "      <td>62.736</td>\n",
       "      <td>6.487</td>\n",
       "      <td>6.180</td>\n",
       "      <td>6.342</td>\n",
       "      <td>GIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2021</td>\n",
       "      <td>15.209524</td>\n",
       "      <td>56.184402</td>\n",
       "      <td>336.492910</td>\n",
       "      <td>65.198997</td>\n",
       "      <td>6.614991e+10</td>\n",
       "      <td>2084.635014</td>\n",
       "      <td>1.113603</td>\n",
       "      <td>11894.0</td>\n",
       "      <td>42.015</td>\n",
       "      <td>4.962</td>\n",
       "      <td>4.478</td>\n",
       "      <td>4.704</td>\n",
       "      <td>GHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2021</td>\n",
       "      <td>6.128571</td>\n",
       "      <td>12.104803</td>\n",
       "      <td>114.434520</td>\n",
       "      <td>61.785000</td>\n",
       "      <td>1.634727e+10</td>\n",
       "      <td>760.440927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25010.0</td>\n",
       "      <td>68.760</td>\n",
       "      <td>4.782</td>\n",
       "      <td>4.738</td>\n",
       "      <td>4.758</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>24.045783</td>\n",
       "      <td>113.489249</td>\n",
       "      <td>63.266998</td>\n",
       "      <td>1.631670e+10</td>\n",
       "      <td>782.360580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49975.0</td>\n",
       "      <td>55.323</td>\n",
       "      <td>8.847</td>\n",
       "      <td>6.887</td>\n",
       "      <td>7.720</td>\n",
       "      <td>MLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Indicator Name  year  \\\n",
       "39              2021   \n",
       "79              2021   \n",
       "119             2021   \n",
       "159             2021   \n",
       "199             2021   \n",
       "239             2021   \n",
       "279             2021   \n",
       "319             2021   \n",
       "359             2021   \n",
       "399             2021   \n",
       "439             2021   \n",
       "479             2021   \n",
       "519             2021   \n",
       "559             2021   \n",
       "\n",
       "Indicator Name  Access to clean fuels and technologies for cooking (% of population)  \\\n",
       "39                                                       1.152381                      \n",
       "79                                                       0.452381                      \n",
       "119                                                      3.142857                      \n",
       "159                                                     32.359524                      \n",
       "199                                                     22.297619                      \n",
       "239                                                     20.733333                      \n",
       "279                                                      0.411905                      \n",
       "319                                                      4.130952                      \n",
       "359                                                      2.709524                      \n",
       "399                                                     39.757143                      \n",
       "439                                                      0.914286                      \n",
       "479                                                     15.209524                      \n",
       "519                                                      6.128571                      \n",
       "559                                                      0.861905                      \n",
       "\n",
       "Indicator Name  Access to electricity (% of population)  \\\n",
       "39                                            14.680897   \n",
       "79                                            12.451786   \n",
       "119                                           29.255348   \n",
       "159                                           47.738296   \n",
       "199                                           65.893630   \n",
       "239                                           55.635514   \n",
       "279                                           15.661907   \n",
       "319                                           33.871515   \n",
       "359                                           39.431974   \n",
       "399                                           32.948903   \n",
       "439                                           27.649023   \n",
       "479                                           56.184402   \n",
       "519                                           12.104803   \n",
       "559                                           24.045783   \n",
       "\n",
       "Indicator Name  Consumer price index (2010 = 100)  \\\n",
       "39                                      69.858202   \n",
       "79                                     104.172660   \n",
       "119                                    116.044206   \n",
       "159                                     80.244155   \n",
       "199                                     71.802009   \n",
       "239                                    118.991106   \n",
       "279                                    297.185330   \n",
       "319                                     74.763121   \n",
       "359                                    196.461489   \n",
       "399                                     71.657125   \n",
       "439                                    327.463207   \n",
       "479                                    336.492910   \n",
       "519                                    114.434520   \n",
       "559                                    113.489249   \n",
       "\n",
       "Indicator Name  Employment to population ratio, 15+, total (%) (modeled ILO estimate)  \\\n",
       "39                                                      66.037003                       \n",
       "79                                                      71.669998                       \n",
       "119                                                     69.830002                       \n",
       "159                                                     42.876999                       \n",
       "199                                                     49.854000                       \n",
       "239                                                     53.574001                       \n",
       "279                                                     53.019001                       \n",
       "319                                                     55.111000                       \n",
       "359                                                     50.965000                       \n",
       "399                                                     39.612999                       \n",
       "439                                                     58.181000                       \n",
       "479                                                     65.198997                       \n",
       "519                                                     61.785000                       \n",
       "559                                                     63.266998                       \n",
       "\n",
       "Indicator Name  GDP (constant 2015 US$)  GDP per capita (constant 2015 US$)  \\\n",
       "39                         1.265073e+09                          627.675020   \n",
       "79                         3.240179e+09                          625.492033   \n",
       "119                        1.569745e+10                         1260.734609   \n",
       "159                        2.424600e+10                         1409.953856   \n",
       "199                        9.534008e+09                         6575.672189   \n",
       "239                        6.531937e+10                         2414.440339   \n",
       "279                        5.128555e+09                          629.939682   \n",
       "319                        5.460540e+09                          644.065112   \n",
       "359                        1.768338e+09                          711.050403   \n",
       "399                        7.372519e+09                         1543.947556   \n",
       "439                        1.302990e+10                          965.375522   \n",
       "479                        6.614991e+10                         2084.635014   \n",
       "519                        1.634727e+10                          760.440927   \n",
       "559                        1.631670e+10                          782.360580   \n",
       "\n",
       "Indicator Name  Oil rents (% of GDP)  \\\n",
       "39                          0.000000   \n",
       "79                          0.000000   \n",
       "119                         0.530840   \n",
       "159                         0.000252   \n",
       "199                        21.880515   \n",
       "239                         0.967656   \n",
       "279                         0.000000   \n",
       "319                         0.000000   \n",
       "359                         0.000000   \n",
       "399                         1.033768   \n",
       "439                         0.000000   \n",
       "479                         1.113603   \n",
       "519                         0.000000   \n",
       "559                         0.000000   \n",
       "\n",
       "Indicator Name  Refugee population by country or territory of asylum  \\\n",
       "39                                                         1846.0      \n",
       "79                                                         8169.0      \n",
       "119                                                        1736.0      \n",
       "159                                                       14479.0      \n",
       "199                                                           NaN      \n",
       "239                                                        4349.0      \n",
       "279                                                         345.0      \n",
       "319                                                       10683.0      \n",
       "359                                                        4418.0      \n",
       "399                                                      101942.0      \n",
       "439                                                        5741.0      \n",
       "479                                                       11894.0      \n",
       "519                                                       25010.0      \n",
       "559                                                       49975.0      \n",
       "\n",
       "Indicator Name  Rural population (% of total population)  \\\n",
       "39                                                55.383   \n",
       "79                                                47.427   \n",
       "119                                               51.028   \n",
       "159                                               51.400   \n",
       "199                                               26.439   \n",
       "239                                               47.820   \n",
       "279                                               56.628   \n",
       "319                                               56.642   \n",
       "359                                               36.778   \n",
       "399                                               43.867   \n",
       "439                                               62.736   \n",
       "479                                               42.015   \n",
       "519                                               68.760   \n",
       "559                                               55.323   \n",
       "\n",
       "Indicator Name  Unemployment, female (% of female labor force) (modeled ILO estimate)  \\\n",
       "39                                                          7.694                       \n",
       "79                                                          3.365                       \n",
       "119                                                         1.860                       \n",
       "159                                                         3.997                       \n",
       "199                                                        10.609                       \n",
       "239                                                         4.144                       \n",
       "279                                                         4.650                       \n",
       "319                                                         3.114                       \n",
       "359                                                        14.820                       \n",
       "399                                                        13.004                       \n",
       "439                                                         6.487                       \n",
       "479                                                         4.962                       \n",
       "519                                                         4.782                       \n",
       "559                                                         8.847                       \n",
       "\n",
       "Indicator Name  Unemployment, male (% of male labor force) (modeled ILO estimate)  \\\n",
       "39                                                          5.932                   \n",
       "79                                                          4.739                   \n",
       "119                                                         1.295                   \n",
       "159                                                         3.544                   \n",
       "199                                                         8.419                   \n",
       "239                                                         2.999                   \n",
       "279                                                         6.023                   \n",
       "319                                                         4.852                   \n",
       "359                                                         8.430                   \n",
       "399                                                        10.780                   \n",
       "439                                                         6.180                   \n",
       "479                                                         4.478                   \n",
       "519                                                         4.738                   \n",
       "559                                                         6.887                   \n",
       "\n",
       "Indicator Name  Unemployment, total (% of total labor force) (modeled ILO estimate)  \\\n",
       "39                                                          6.759                     \n",
       "79                                                          4.095                     \n",
       "119                                                         1.574                     \n",
       "159                                                         3.723                     \n",
       "199                                                         9.245                     \n",
       "239                                                         3.468                     \n",
       "279                                                         5.333                     \n",
       "319                                                         4.004                     \n",
       "359                                                        11.212                     \n",
       "399                                                        11.463                     \n",
       "439                                                         6.342                     \n",
       "479                                                         4.704                     \n",
       "519                                                         4.758                     \n",
       "559                                                         7.720                     \n",
       "\n",
       "Indicator Name Country Code  \n",
       "39                      GNB  \n",
       "79                      LBR  \n",
       "119                     BEN  \n",
       "159                     SEN  \n",
       "199                     GNQ  \n",
       "239                     CIV  \n",
       "279                     SLE  \n",
       "319                     TGO  \n",
       "359                     GMB  \n",
       "399                     MRT  \n",
       "439                     GIN  \n",
       "479                     GHA  \n",
       "519                     BFA  \n",
       "559                     MLI  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to check if 2021 data is available for all countries, in that case forecast only for 2022\n",
    "df_wbi_final_test = df_wbi_final.reset_index()\n",
    "df_wbi_final_test[df_wbi_final_test[\"year\"] == \"2021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6a91321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indicator Name\n",
       "year                                                                      0\n",
       "Access to clean fuels and technologies for cooking (% of population)      0\n",
       "Access to electricity (% of population)                                   0\n",
       "Consumer price index (2010 = 100)                                         0\n",
       "Employment to population ratio, 15+, total (%) (modeled ILO estimate)     0\n",
       "GDP (constant 2015 US$)                                                   0\n",
       "GDP per capita (constant 2015 US$)                                        0\n",
       "Oil rents (% of GDP)                                                      0\n",
       "Refugee population by country or territory of asylum                     40\n",
       "Rural population (% of total population)                                  0\n",
       "Unemployment, female (% of female labor force) (modeled ILO estimate)     0\n",
       "Unemployment, male (% of male labor force) (modeled ILO estimate)         0\n",
       "Unemployment, total (% of total labor force) (modeled ILO estimate)       0\n",
       "Country Code                                                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if any entries are not present \n",
    "df_wbi_final_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46db9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate averages and impute missing values wit averages\n",
    "#missing values are only present for country GNQ Refugee Population. as no values at all are available, this gets replaced with 0. \n",
    "df_wbi_final.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce3ea556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Access to clean fuels and technologies for cooking (% of population)',\n",
       "       'Access to electricity (% of population)',\n",
       "       'Consumer price index (2010 = 100)',\n",
       "       'Employment to population ratio, 15+, total (%) (modeled ILO estimate)',\n",
       "       'GDP (constant 2015 US$)', 'GDP per capita (constant 2015 US$)',\n",
       "       'Oil rents (% of GDP)',\n",
       "       'Refugee population by country or territory of asylum',\n",
       "       'Rural population (% of total population)',\n",
       "       'Unemployment, female (% of female labor force) (modeled ILO estimate)',\n",
       "       'Unemployment, male (% of male labor force) (modeled ILO estimate)',\n",
       "       'Unemployment, total (% of total labor force) (modeled ILO estimate)',\n",
       "       'Country Code'],\n",
       "      dtype='object', name='Indicator Name')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wbi_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdad6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(df_wbi_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f007713",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.remove(\"Country Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f369b3a",
   "metadata": {},
   "source": [
    "**World Bank Indicators Forecast**\n",
    "\n",
    "WBI Indicators are only present until 2020 and need to be forecasted for 2021 and 2022. This predictor forecasting approach is verified in a separate notebook, called \"AutoRegressor Approach Verification\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45a05dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Access to clean fuels and technologies for cooking (% of population)',\n",
       " 'Access to electricity (% of population)',\n",
       " 'Consumer price index (2010 = 100)',\n",
       " 'Employment to population ratio, 15+, total (%) (modeled ILO estimate)',\n",
       " 'GDP (constant 2015 US$)',\n",
       " 'GDP per capita (constant 2015 US$)',\n",
       " 'Oil rents (% of GDP)',\n",
       " 'Refugee population by country or territory of asylum',\n",
       " 'Rural population (% of total population)',\n",
       " 'Unemployment, female (% of female labor force) (modeled ILO estimate)',\n",
       " 'Unemployment, male (% of male labor force) (modeled ILO estimate)',\n",
       " 'Unemployment, total (% of total labor force) (modeled ILO estimate)']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bc7b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecasting of the values \n",
    "df_wbi_final_copy = df_wbi_final.copy()\n",
    "#define necessary lists\n",
    "country_codes = set(df_wbi_final[\"Country Code\"])\n",
    "year_list3 = [2022]\n",
    "# for the time series forecasting, the date dimension needs to be the idnex\n",
    "df_wbi_final = df_wbi_final.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae8fbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to verify the chosen forecasting approach\n",
    "df_wbi_final.to_excel(\"autoreg_test_wbi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07109855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to create predictions for the next year\n",
    "def create_predictions(data, columns, States, year_list):\n",
    "    df_pred = pd.DataFrame()\n",
    "    df_new = pd.DataFrame()\n",
    "    df = pd.DataFrame()\n",
    "    steps = len(year_list)\n",
    "     \n",
    "    for j in States: \n",
    "        data_filtered = data[data['Country Code'] == j]\n",
    "        data_filtered.drop(columns = ['Country Code'], inplace = True)\n",
    "        data_train = data_filtered\n",
    "        \n",
    "        for i in columns: \n",
    "            forecaster = ForecasterAutoreg(regressor = RandomForestRegressor(random_state=123), lags = 15)\n",
    "            \n",
    "            forecaster.fit(y=data_train[i])\n",
    "            \n",
    "            predictions = forecaster.predict(steps = steps)\n",
    "            predictions.to_frame()\n",
    "            df_pred[i] = predictions\n",
    "            df_pred['Country Code'] = j\n",
    "            df_pred['year'] = year_list\n",
    "        df_new = df_new.append(df_pred)\n",
    "    df = df.append(df_new)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the prediction function and let it run for the coming year\n",
    "df = create_predictions(df_wbi_final, predictors, country_codes, year_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wbi_final_copy = df_wbi_final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the forecasted data to the previous dataset\n",
    "df_new = pd.concat([df_wbi_final_copy, df], axis = 0)\n",
    "\n",
    "df_new_copy = df_new.copy()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf28fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export file for immediate processing\n",
    "df_new.to_pickle(\"df_new.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import file for immediate processing\n",
    "import pandas as pd\n",
    "df_wbi = pd.read_pickle(\"df_new.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f65820",
   "metadata": {},
   "source": [
    "**HDI Forecast**\n",
    "\n",
    "HDI Data is only available until 2019. Future values will be forecasted while past values, so values prior to 1990, will be imputed with the average. This predictor forecasting approach for future values is verified in a separate notebook, called \"AutoRegressor Approach Verification\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e68f0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type of this column needs to be changed\n",
    "test_df[\"population (000'000)\"] = test_df[\"population (000'000)\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d3bf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['MonthYear', 'Year', 'ActionGeo_CountryCode', 'ActionGeo_ADM1Code',\n",
    "       'number of conflicts', 'iso_code', 'country_x', 'e year', 'level',\n",
    "       'region', 'gender development index (GDI)',\n",
    "       'human development index (HDI)', 'health index', 'income index',\n",
    "       'educational index', 'expected years of schooling',\n",
    "       'mean years of scholing', 'life expectancy', \"GNI per capita (000'000)\",\n",
    "       \"population (000'000)\", 'adm1', 'country_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57834321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into two parts, future and past. As the NaN values will be treated differently depending on that. \n",
    "test_df_future = test_df[test_df[\"Year\"] > 2019 ]\n",
    "test_df_past = test_df[test_df[\"Year\"] <= 2019 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41fd9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      GH\n",
       "3      LI\n",
       "4      ML\n",
       "5      SG\n",
       "7      EK\n",
       "8      GA\n",
       "10     GV\n",
       "11     IV\n",
       "14     MR\n",
       "16     WI\n",
       "19     TO\n",
       "31     SL\n",
       "59     UV\n",
       "60     BN\n",
       "167    PU\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all countries and write them into a list\n",
    "countries = test_df_past['ActionGeo_CountryCode'].apply(pd.Series).stack().reset_index(drop=True).drop_duplicates()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81872b",
   "metadata": {},
   "source": [
    "The HDI data does not start in the same year for every Country. Therefore, the missing values exist for different combinations of MonthYears and States. The missing values of the past will be replaced by the average for that specific region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dffe968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the mean per state for each numeric column\n",
    "grouped_df_adm1 = test_df_past.groupby([\"ActionGeo_ADM1Code\"]).mean()\n",
    "grouped_df_adm1.drop(columns = [\"Year\", \"year\"], inplace = True)\n",
    "grouped_df_adm1 = grouped_df_adm1.fillna(0)\n",
    "grouped_df_adm1 = grouped_df_adm1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8686a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>number of conflicts</th>\n",
       "      <th>gender development index (GDI)</th>\n",
       "      <th>human development index (HDI)</th>\n",
       "      <th>health index</th>\n",
       "      <th>income index</th>\n",
       "      <th>educational index</th>\n",
       "      <th>expected years of schooling</th>\n",
       "      <th>mean years of scholing</th>\n",
       "      <th>life expectancy</th>\n",
       "      <th>GNI per capita (000'000)</th>\n",
       "      <th>population (000'000)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BN00</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>39.010965</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.455367</td>\n",
       "      <td>0.577300</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>8.990000</td>\n",
       "      <td>2.706667</td>\n",
       "      <td>57.523333</td>\n",
       "      <td>7.8489</td>\n",
       "      <td>8050.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BN01</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.822583</td>\n",
       "      <td>0.396333</td>\n",
       "      <td>0.555967</td>\n",
       "      <td>0.451433</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>7.497100</td>\n",
       "      <td>1.401967</td>\n",
       "      <td>56.139667</td>\n",
       "      <td>7.5935</td>\n",
       "      <td>1162.139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BN02</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844833</td>\n",
       "      <td>0.547333</td>\n",
       "      <td>0.602433</td>\n",
       "      <td>0.556900</td>\n",
       "      <td>0.493900</td>\n",
       "      <td>11.333867</td>\n",
       "      <td>5.370867</td>\n",
       "      <td>59.156267</td>\n",
       "      <td>8.2915</td>\n",
       "      <td>1627.724367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BN03</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>0.387667</td>\n",
       "      <td>0.576700</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.219967</td>\n",
       "      <td>6.110500</td>\n",
       "      <td>1.506667</td>\n",
       "      <td>57.485800</td>\n",
       "      <td>7.6996</td>\n",
       "      <td>1543.876467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BN04</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808583</td>\n",
       "      <td>0.445233</td>\n",
       "      <td>0.580367</td>\n",
       "      <td>0.454033</td>\n",
       "      <td>0.345467</td>\n",
       "      <td>10.070200</td>\n",
       "      <td>1.973967</td>\n",
       "      <td>57.722833</td>\n",
       "      <td>7.6105</td>\n",
       "      <td>1011.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>UV88</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.373850</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.424750</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>56.360000</td>\n",
       "      <td>7.4169</td>\n",
       "      <td>15590.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>UV89</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.217105</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.373850</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.424750</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>56.360000</td>\n",
       "      <td>7.4169</td>\n",
       "      <td>15590.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>UV90</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>3.798246</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.373850</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.424750</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>56.360000</td>\n",
       "      <td>7.4169</td>\n",
       "      <td>15590.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>UV91</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>0.852909</td>\n",
       "      <td>0.373850</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.424750</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>6.360000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>56.360000</td>\n",
       "      <td>7.4169</td>\n",
       "      <td>15590.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>WI00</td>\n",
       "      <td>200056.5</td>\n",
       "      <td>7.778509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ActionGeo_ADM1Code  MonthYear  number of conflicts  \\\n",
       "0                 BN00   200056.5            39.010965   \n",
       "1                 BN01   200056.5             0.000000   \n",
       "2                 BN02   200056.5             0.000000   \n",
       "3                 BN03   200056.5             0.000000   \n",
       "4                 BN04   200056.5             0.000000   \n",
       "..                 ...        ...                  ...   \n",
       "200               UV88   200056.5             0.657895   \n",
       "201               UV89   200056.5             0.217105   \n",
       "202               UV90   200056.5             3.798246   \n",
       "203               UV91   200056.5             0.109649   \n",
       "204               WI00   200056.5             7.778509   \n",
       "\n",
       "     gender development index (GDI)  human development index (HDI)  \\\n",
       "0                          0.832833                       0.455367   \n",
       "1                          0.822583                       0.396333   \n",
       "2                          0.844833                       0.547333   \n",
       "3                          0.849250                       0.387667   \n",
       "4                          0.808583                       0.445233   \n",
       "..                              ...                            ...   \n",
       "200                        0.852909                       0.373850   \n",
       "201                        0.852909                       0.373850   \n",
       "202                        0.852909                       0.373850   \n",
       "203                        0.852909                       0.373850   \n",
       "204                        0.000000                       0.000000   \n",
       "\n",
       "     health index  income index  educational index  \\\n",
       "0        0.577300      0.489933           0.340000   \n",
       "1        0.555967      0.451433           0.254900   \n",
       "2        0.602433      0.556900           0.493900   \n",
       "3        0.576700      0.467300           0.219967   \n",
       "4        0.580367      0.454033           0.345467   \n",
       "..            ...           ...                ...   \n",
       "200      0.559450      0.424750           0.222700   \n",
       "201      0.559450      0.424750           0.222700   \n",
       "202      0.559450      0.424750           0.222700   \n",
       "203      0.559450      0.424750           0.222700   \n",
       "204      0.000000      0.000000           0.000000   \n",
       "\n",
       "     expected years of schooling  mean years of scholing  life expectancy  \\\n",
       "0                       8.990000                2.706667        57.523333   \n",
       "1                       7.497100                1.401967        56.139667   \n",
       "2                      11.333867                5.370867        59.156267   \n",
       "3                       6.110500                1.506667        57.485800   \n",
       "4                      10.070200                1.973967        57.722833   \n",
       "..                           ...                     ...              ...   \n",
       "200                     6.360000                1.380000        56.360000   \n",
       "201                     6.360000                1.380000        56.360000   \n",
       "202                     6.360000                1.380000        56.360000   \n",
       "203                     6.360000                1.380000        56.360000   \n",
       "204                     0.000000                0.000000         0.000000   \n",
       "\n",
       "     GNI per capita (000'000)  population (000'000)  \n",
       "0                      7.8489           8050.199000  \n",
       "1                      7.5935           1162.139100  \n",
       "2                      8.2915           1627.724367  \n",
       "3                      7.6996           1543.876467  \n",
       "4                      7.6105           1011.579400  \n",
       "..                        ...                   ...  \n",
       "200                    7.4169          15590.256700  \n",
       "201                    7.4169          15590.256700  \n",
       "202                    7.4169          15590.256700  \n",
       "203                    7.4169          15590.256700  \n",
       "204                    0.0000              0.000000  \n",
       "\n",
       "[205 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df_adm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d16a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2038215063.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_past.drop(columns = ['iso_code', 'country_x', 'year', 'adm1', 'country_y'], inplace = True )\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2038215063.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_future.drop(columns = ['iso_code', 'country_x', 'year', 'adm1', 'country_y'], inplace = True )\n"
     ]
    }
   ],
   "source": [
    "#drop unnecessary columns\n",
    "test_df_past.drop(columns = ['iso_code', 'country_x', 'year', 'adm1', 'country_y'], inplace = True )\n",
    "test_df_future.drop(columns = ['iso_code', 'country_x', 'year', 'adm1', 'country_y'], inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3784e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write all numeric columns into a list\n",
    "numeric_columns = ['gender development index (GDI)', 'human development index (HDI)',\n",
    "       'health index', 'income index', 'educational index',\n",
    "       'expected years of schooling', 'mean years of scholing',\n",
    "       'life expectancy', \"GNI per capita (000'000)\", \"population (000'000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3450bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill Nan values for the past data with the average of the state\n",
    "for index, row in test_df_past.iterrows():\n",
    "    for column in numeric_columns:    \n",
    "        if pd.isna(row[column]) == True:\n",
    "            test_df_past.at[index, column] = grouped_df_adm1[grouped_df_adm1[\"ActionGeo_ADM1Code\"] == row[\"ActionGeo_ADM1Code\"]][column]\n",
    "        else: \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b99d4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57352"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that no NaNs remain ---- NA comes from LEVEL/REGION field which are not populated\n",
    "test_df_past.isna().sum().sum()\n",
    "#test_df_past[\"income index\"].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35218dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98408"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "324ac450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\3905887967.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_past.drop_duplicates(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#in the last step, we remove any available duplicates by comparing all columns\n",
    "test_df_past.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62d95383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93480"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_past)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5c3d0",
   "metadata": {},
   "source": [
    "Now we take care of the future values that are missing (starting at 2019). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a0b3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write lists for forecasted values \n",
    "adm1 = set(test_df_future[\"ActionGeo_ADM1Code\"])\n",
    "year_list1 = [202001, 202002, 202003, 202004, 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012]\n",
    "year_list2 = [202101, 202102, 202103, 202104, 202105, 202106, 202107, 202108, 202109, 202110, 202111, 202112]\n",
    "year_list3 = [202201, 202202, 202203, 202204, 202205, 202206, 202207, 202208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5710cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\1269219251.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_past['MonthYear_2'] = test_df_past['MonthYear']\n"
     ]
    }
   ],
   "source": [
    "# for the time series forecasting, the date dimension needs to be the idnex\n",
    "test_df_past['MonthYear_2'] = test_df_past['MonthYear']\n",
    "test_df_past = test_df_past.set_index('MonthYear_2')\n",
    "test_df_past = test_df_past.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c144f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we save a copy of the dataframe which we will later on merge with the forecasted data\n",
    "test_df_past_copy = test_df_past.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19acdf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93480, 93480)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df_past), len(test_df_past_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7a9b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the data to excel file for the approach verification notebook\n",
    "test_df_past.to_excel(\"autoreg_hdi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0ec03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to create predictions for the next year\n",
    "def create_predictions(data, predictors, States, year_list):\n",
    "    df_pred = pd.DataFrame()\n",
    "    df_new = pd.DataFrame()\n",
    "    df = pd.DataFrame()\n",
    "    steps = len(year_list)\n",
    "     \n",
    "    for j in States: \n",
    "        data_filtered = data[data['ActionGeo_ADM1Code'] == j]\n",
    "        data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
    "            \"ActionGeo_ADM1Code\",\n",
    "\n",
    "                                     ], inplace = True)\n",
    "        data_train = data_filtered\n",
    "        \n",
    "        for i in predictors: \n",
    "            forecaster = ForecasterAutoreg(regressor = RandomForestRegressor(random_state=123), lags = 62)\n",
    "            \n",
    "            forecaster.fit(y=data_train[i])\n",
    "            \n",
    "            predictions = forecaster.predict(steps = steps)\n",
    "            predictions.to_frame()\n",
    "            df_pred[i] = predictions\n",
    "            df_pred['ActionGeo_ADM1Code'] = j\n",
    "            df_pred['MonthYear'] = year_list\n",
    "        df_new = df_new.append(df_pred)\n",
    "    df = df.append(df_new)\n",
    "   \n",
    "    return df\n",
    "\n",
    "#call the prediction function and let it run for the coming year\n",
    "#df = create_predictions(test_df_past, numeric_columns, adm1, year_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c73e2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_new = df_new.append(df_pred)\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_7456\\2839625428.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered.drop(columns = [#\"Year\", \"ActionGeo_CountryCode\",\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\utils\\utils.py:256: UserWarning: `y` has no DatetimeIndex nor RangeIndex index. Index is overwritten with a RangeIndex.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#call the prediction function and let it run for the coming year\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_list1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36mcreate_predictions\u001b[1;34m(data, predictors, States, year_list)\u001b[0m\n\u001b[0;32m     19\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterAutoreg(regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m), lags \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m62\u001b[39m)\n\u001b[0;32m     21\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mfit(y\u001b[38;5;241m=\u001b[39mdata_train[i])\n\u001b[1;32m---> 23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m predictions\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m     25\u001b[0m df_pred[i] \u001b[38;5;241m=\u001b[39m predictions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\ForecasterAutoreg\\ForecasterAutoreg.py:493\u001b[0m, in \u001b[0;36mForecasterAutoreg.predict\u001b[1;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m     last_window_values, last_window_index \u001b[38;5;241m=\u001b[39m preprocess_last_window(\n\u001b[0;32m    490\u001b[0m                                                 last_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_window\n\u001b[0;32m    491\u001b[0m                                             )\n\u001b[1;32m--> 493\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m                \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_window_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[0;32m    500\u001b[0m                 data  \u001b[38;5;241m=\u001b[39m predictions,\n\u001b[0;32m    501\u001b[0m                 index \u001b[38;5;241m=\u001b[39m expand_index(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    506\u001b[0m               )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\skforecast\\ForecasterAutoreg\\ForecasterAutoreg.py:415\u001b[0m, in \u001b[0;36mForecasterAutoreg._recursive_predict\u001b[1;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# Suppress scikitlearn warning: \"X does not have valid feature names,\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# but NoOpTransformer was fitted with feature names\".\u001b[39;00m\n\u001b[0;32m    414\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 415\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m     predictions[i] \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39mravel()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# Update `last_window` values. The first position is discarded and \u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# the new prediction is added at the end.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:1004\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m-> 1004\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m y_hat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:664\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\tree\\_classes.py:506\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    504\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 506\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# Classification\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#call the prediction function and let it run for the coming year\n",
    "df = create_predictions(test_df_past, numeric_columns, adm1, year_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the old dataset with the forecasted values\n",
    "df_new = pd.DataFrame()\n",
    "df_new = pd.concat([test_df_past, df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_copy = df_new.copy()\n",
    "\n",
    "df_new = df_new.set_index('MonthYear')\n",
    "df_new = df_new.sort_index()\n",
    "df_new\n",
    "\n",
    "df_new_copy.drop(columns = ['Year', 'ActionGeo_CountryCode', 'level', 'region', 'number of conflicts'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(columns = ['number of conflicts'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo the forecasting for the 2nd year\n",
    "df2 = create_predictions(df_new, numeric_columns, adm1, year_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b366eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the forescasted values for 2021 to the previous dataset\n",
    "df2_copy = df2.copy()\n",
    "\n",
    "df_new = pd.concat([df_new_copy, df2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the new dataset\n",
    "df_new_copy2 = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set MonthYear column as the index and sort the data accordingly \n",
    "df_new = df_new.set_index('MonthYear')\n",
    "df_new = df_new.sort_index()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9bae5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#redo the forecasting for the 3rd year\n",
    "df3 = create_predictions(df_new, numeric_columns, adm1, year_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b04644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that no NaNs remain in the created dataframe\n",
    "df3.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate old dataset and newly forecasted values for 2022\n",
    "df_new = pd.concat([df_new_copy2, df3], axis = 0)\n",
    "df_new = df_new.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fa505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_copy_final = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5efcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e165f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rejoin number of conflicts, ActionGeo_CountryCode to the df_new dataframe\n",
    "#test_df.drop(columns = ['iso_code', 'country_x', 'year', 'level',\n",
    "#       'region', 'gender development index (GDI)',\n",
    "#       'human development index (HDI)', 'health index', 'income index',\n",
    "#       'educational index', 'expected years of schooling',\n",
    "#       'mean years of scholing', 'life expectancy', \"GNI per capita (000'000)\",\n",
    "#       \"population (000'000)\", 'adm1', 'country_y'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the new HDI values to the other dataset\n",
    "merged = df_new.merge(test_df, how =\"left\", left_on = ['MonthYear', 'ActionGeo_ADM1Code'], right_on = ['MonthYear', 'ActionGeo_ADM1Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new), len(test_df), len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec92daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any existing duplicate entries by comparing all columns\n",
    "merged.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add the country codes via the iso codes to the WBI dataset\n",
    "matched_states_subset = matched_states[['country', 'iso_code']]\n",
    "matched_states_subset.drop_duplicates(inplace = True)\n",
    "\n",
    "df_wbi_with_code = pd.merge(df_wbi, matched_states_subset, how = \"left\", left_on = ['Country Code'], right_on = ['iso_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the year type to int to enable a correct merge (both columns need to be of the same type)\n",
    "df_wbi_with_code['year'] = df_wbi_with_code['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the WBI data with the previously merged dataset\n",
    "merged_2 = pd.merge(merged, df_wbi_with_code, how =\"left\", left_on = ['Year', 'ActionGeo_CountryCode'], right_on = ['year', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that the length of the datasets have not changed after adding additional columns\n",
    "len(merged), len(merged_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c11c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values, and upon closer inspection we find out that values are missing for Western Sahara\n",
    "#as there were no WBI for this country\n",
    "merged_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c431f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following constants will be imputed for missing values for Western Sahara\n",
    "merged_2['year'] = merged_2['Year']\n",
    "merged_2['Country Code'] = merged_2['Country Code'].fillna('ESH')\n",
    "merged_2['country'] = merged_2['ActionGeo_CountryCode']\n",
    "merged_2['iso_code'] = merged_2['iso_code'].fillna('ESH')\n",
    "\n",
    "#all numeric values will be filled with NA\n",
    "merged_2 = merged_2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd274ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ensure that there are no more missing values\n",
    "merged_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the final dataframe which includes GDELT data as well as the HDI and WBI predictors so that it can be used in \n",
    "#the following notebook\n",
    "merged_2.to_pickle(\"merged_2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4b99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataframe which has the merged GDELT, HDI AND WDI data\n",
    "import pandas as pd\n",
    "df_complete = pd.read_pickle(\"merged_2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13345e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that no NaNs remain as the Deep Learning model cannot handle missing datapoints\n",
    "df_complete.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e62573f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length of the dataframe\n",
    "len(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55fcfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>ActionGeo_ADM1Code</th>\n",
       "      <th>gender development index (GDI)</th>\n",
       "      <th>human development index (HDI)</th>\n",
       "      <th>health index</th>\n",
       "      <th>income index</th>\n",
       "      <th>educational index</th>\n",
       "      <th>expected years of schooling</th>\n",
       "      <th>mean years of scholing</th>\n",
       "      <th>life expectancy</th>\n",
       "      <th>...</th>\n",
       "      <th>GDP per capita (constant 2015 US$)</th>\n",
       "      <th>Oil rents (% of GDP)</th>\n",
       "      <th>Refugee population by country or territory of asylum</th>\n",
       "      <th>Rural population (% of total population)</th>\n",
       "      <th>Unemployment, female (% of female labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, male (% of male labor force) (modeled ILO estimate)</th>\n",
       "      <th>Unemployment, total (% of total labor force) (modeled ILO estimate)</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>country</th>\n",
       "      <th>iso_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198201</td>\n",
       "      <td>GH00</td>\n",
       "      <td>0.890083</td>\n",
       "      <td>0.529633</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>6.296667</td>\n",
       "      <td>59.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>818.424484</td>\n",
       "      <td>0.082957</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>68.386</td>\n",
       "      <td>6.484355</td>\n",
       "      <td>5.843258</td>\n",
       "      <td>6.154000</td>\n",
       "      <td>GHA</td>\n",
       "      <td>GH</td>\n",
       "      <td>GHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198201</td>\n",
       "      <td>MR08</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.575933</td>\n",
       "      <td>0.696267</td>\n",
       "      <td>0.730633</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>7.629333</td>\n",
       "      <td>5.021800</td>\n",
       "      <td>65.256600</td>\n",
       "      <td>...</td>\n",
       "      <td>1473.186563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38883.176471</td>\n",
       "      <td>69.705</td>\n",
       "      <td>12.279548</td>\n",
       "      <td>9.046226</td>\n",
       "      <td>10.030677</td>\n",
       "      <td>MRT</td>\n",
       "      <td>MR</td>\n",
       "      <td>MRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198201</td>\n",
       "      <td>BN10</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>0.387667</td>\n",
       "      <td>0.576700</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.219967</td>\n",
       "      <td>6.110500</td>\n",
       "      <td>1.506667</td>\n",
       "      <td>57.485800</td>\n",
       "      <td>...</td>\n",
       "      <td>824.012210</td>\n",
       "      <td>0.484284</td>\n",
       "      <td>10130.000000</td>\n",
       "      <td>71.308</td>\n",
       "      <td>1.179129</td>\n",
       "      <td>1.458742</td>\n",
       "      <td>1.346839</td>\n",
       "      <td>BEN</td>\n",
       "      <td>BN</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198201</td>\n",
       "      <td>LI04</td>\n",
       "      <td>0.847250</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.537810</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>0.295714</td>\n",
       "      <td>8.139905</td>\n",
       "      <td>2.087143</td>\n",
       "      <td>54.959667</td>\n",
       "      <td>...</td>\n",
       "      <td>664.549655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44174.324324</td>\n",
       "      <td>62.827</td>\n",
       "      <td>2.282258</td>\n",
       "      <td>2.481613</td>\n",
       "      <td>2.387903</td>\n",
       "      <td>LBR</td>\n",
       "      <td>LI</td>\n",
       "      <td>LBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198201</td>\n",
       "      <td>MR07</td>\n",
       "      <td>0.863667</td>\n",
       "      <td>0.484567</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>8.018067</td>\n",
       "      <td>3.578667</td>\n",
       "      <td>58.291167</td>\n",
       "      <td>...</td>\n",
       "      <td>1473.186563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38883.176471</td>\n",
       "      <td>69.705</td>\n",
       "      <td>12.279548</td>\n",
       "      <td>9.046226</td>\n",
       "      <td>10.030677</td>\n",
       "      <td>MRT</td>\n",
       "      <td>MR</td>\n",
       "      <td>MRT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MonthYear ActionGeo_ADM1Code  gender development index (GDI)  \\\n",
       "0     198201               GH00                        0.890083   \n",
       "1     198201               MR08                        0.888000   \n",
       "2     198201               BN10                        0.849250   \n",
       "3     198201               LI04                        0.847250   \n",
       "4     198201               MR07                        0.863667   \n",
       "\n",
       "   human development index (HDI)  health index  income index  \\\n",
       "0                       0.529633      0.607433      0.525700   \n",
       "1                       0.575933      0.696267      0.730633   \n",
       "2                       0.387667      0.576700      0.467300   \n",
       "3                       0.379000      0.537810      0.343810   \n",
       "4                       0.484567      0.589100      0.571667   \n",
       "\n",
       "   educational index  expected years of schooling  mean years of scholing  \\\n",
       "0           0.466200                     9.230000                6.296667   \n",
       "1           0.379300                     7.629333                5.021800   \n",
       "2           0.219967                     6.110500                1.506667   \n",
       "3           0.295714                     8.139905                2.087143   \n",
       "4           0.342033                     8.018067                3.578667   \n",
       "\n",
       "   life expectancy  ...  GDP per capita (constant 2015 US$)  \\\n",
       "0        59.490000  ...                          818.424484   \n",
       "1        65.256600  ...                         1473.186563   \n",
       "2        57.485800  ...                          824.012210   \n",
       "3        54.959667  ...                          664.549655   \n",
       "4        58.291167  ...                         1473.186563   \n",
       "\n",
       "   Oil rents (% of GDP)  Refugee population by country or territory of asylum  \\\n",
       "0              0.082957                                         100.000000      \n",
       "1              0.000000                                       38883.176471      \n",
       "2              0.484284                                       10130.000000      \n",
       "3              0.000000                                       44174.324324      \n",
       "4              0.000000                                       38883.176471      \n",
       "\n",
       "  Rural population (% of total population)  \\\n",
       "0                                   68.386   \n",
       "1                                   69.705   \n",
       "2                                   71.308   \n",
       "3                                   62.827   \n",
       "4                                   69.705   \n",
       "\n",
       "   Unemployment, female (% of female labor force) (modeled ILO estimate)  \\\n",
       "0                                           6.484355                       \n",
       "1                                          12.279548                       \n",
       "2                                           1.179129                       \n",
       "3                                           2.282258                       \n",
       "4                                          12.279548                       \n",
       "\n",
       "   Unemployment, male (% of male labor force) (modeled ILO estimate)  \\\n",
       "0                                           5.843258                   \n",
       "1                                           9.046226                   \n",
       "2                                           1.458742                   \n",
       "3                                           2.481613                   \n",
       "4                                           9.046226                   \n",
       "\n",
       "   Unemployment, total (% of total labor force) (modeled ILO estimate)  \\\n",
       "0                                           6.154000                     \n",
       "1                                          10.030677                     \n",
       "2                                           1.346839                     \n",
       "3                                           2.387903                     \n",
       "4                                          10.030677                     \n",
       "\n",
       "   Country Code  country  iso_code  \n",
       "0           GHA       GH       GHA  \n",
       "1           MRT       MR       MRT  \n",
       "2           BEN       BN       BEN  \n",
       "3           LBR       LI       LBR  \n",
       "4           MRT       MR       MRT  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look at the data\n",
    "df_complete.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2bd46",
   "metadata": {},
   "source": [
    "### 4) Handling Categorical Variables\n",
    "Before training the neural networks, the categorical values have to be transformed into numeric variables. Different strategies are performed for the the different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aca0f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MonthYear                                                                  int64\n",
       "ActionGeo_ADM1Code                                                        object\n",
       "gender development index (GDI)                                           float64\n",
       "human development index (HDI)                                            float64\n",
       "health index                                                             float64\n",
       "income index                                                             float64\n",
       "educational index                                                        float64\n",
       "expected years of schooling                                              float64\n",
       "mean years of scholing                                                   float64\n",
       "life expectancy                                                          float64\n",
       "GNI per capita (000'000)                                                 float64\n",
       "population (000'000)                                                     float64\n",
       "Year                                                                       int32\n",
       "ActionGeo_CountryCode                                                     object\n",
       "number of conflicts                                                        int64\n",
       "year                                                                       int32\n",
       "Access to clean fuels and technologies for cooking (% of population)     float64\n",
       "Access to electricity (% of population)                                  float64\n",
       "Consumer price index (2010 = 100)                                        float64\n",
       "Employment to population ratio, 15+, total (%) (modeled ILO estimate)    float64\n",
       "GDP (constant 2015 US$)                                                  float64\n",
       "GDP per capita (constant 2015 US$)                                       float64\n",
       "Oil rents (% of GDP)                                                     float64\n",
       "Refugee population by country or territory of asylum                     float64\n",
       "Rural population (% of total population)                                 float64\n",
       "Unemployment, female (% of female labor force) (modeled ILO estimate)    float64\n",
       "Unemployment, male (% of male labor force) (modeled ILO estimate)        float64\n",
       "Unemployment, total (% of total labor force) (modeled ILO estimate)      float64\n",
       "Country Code                                                              object\n",
       "country                                                                   object\n",
       "iso_code                                                                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data types, we see that ActionGeo_ADM1Code and ActionGeo_CountryCode are categorical variables that need to be \n",
    "#transformed into numeric values\n",
    "df_complete.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077f66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all countries and do a one-hot-encoding\n",
    "countries = df_complete['ActionGeo_CountryCode'].apply(pd.Series).stack().reset_index(drop=True).drop_duplicates()\n",
    "for a in [item for item in countries]:\n",
    "    df_complete[a] = df_complete['ActionGeo_CountryCode'].apply(lambda x: int(a in x.upper()))\n",
    "df_complete.drop(columns = ['ActionGeo_CountryCode'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ce9a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that no NaNs remain\n",
    "df_complete.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007efb5d",
   "metadata": {},
   "source": [
    "Create an autoencoder for ADM1 subdivision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the ADM1 codes as predictors and conflicts as the prediction target as a binary variable\n",
    "adm1_codes = df_complete[['ActionGeo_ADM1Code']]\n",
    "adm1_codes_y = (df_complete['number of conflicts']>0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c8462e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write all adm1 codes into a list\n",
    "adm1 = adm1_codes['ActionGeo_ADM1Code'].apply(pd.Series).stack().reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be7eef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n",
      "C:\\Users\\Shadow\\AppData\\Local\\Temp\\ipykernel_12864\\2090237104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))\n"
     ]
    }
   ],
   "source": [
    "#create a manual one hot encoding for this dimension\n",
    "for a in [item for item in adm1]:\n",
    "    adm1_codes[a] = adm1_codes['ActionGeo_ADM1Code'].apply(lambda x: int(a in x.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503d03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the original column from the dataframe\n",
    "adm1_codes.drop(columns = ['ActionGeo_ADM1Code'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52196270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform a train-test-split\n",
    "adm1_codes_train, adm1_codes_test, adm1_codes_y_train, adm1_codes_y_test = train_test_split(adm1_codes, adm1_codes_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "197d43a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8147241103558577\n",
      "0.8136370451819273\n"
     ]
    }
   ],
   "source": [
    "#train a simple logistic regression to see how well we can do a binary prediction of conflicts with the one-hot-encoded\n",
    "#variables vs the decoded variables \n",
    "lg = LogisticRegression(class_weight = 'balanced')#, solver='liblinear')\n",
    "\n",
    "lg.fit(adm1_codes_train, adm1_codes_y_train)\n",
    "print(lg.score(adm1_codes_test, adm1_codes_y_test))\n",
    "print(lg.score(adm1_codes_train, adm1_codes_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762422b",
   "metadata": {},
   "source": [
    "0.8147241103558577\n",
    "0.8136370451819273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817f4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix to evaluate the logistic regression\n",
    "adm1_codes_y_pred = lg.predict(adm1_codes_test)\n",
    "cf_matrix = confusion_matrix(adm1_codes_y_pred, adm1_codes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b29f52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(adm1_codes_y_pred, adm1_codes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f4809a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(cf_matrix, annot = True,  cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2a4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense\n",
    "autoencoder = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0ae06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80032, 205)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm1_codes_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ad506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create neural network for the autoencoder\n",
    "input_data = Input(shape=(adm1_codes_train.shape[1],))\n",
    "encoder = Dense(164, activation='relu')(input_data)\n",
    "encoder = Dense(128, activation='relu')(encoder)\n",
    "encoder = Dense(32, activation='relu')(encoder)\n",
    "encoder = Dense(16, activation='relu')(encoder)\n",
    "encoder = Dense(5, activation='relu')(encoder)\n",
    "#encoder = Dense(5, activation='relu')(encoder)\n",
    "#----------BOTTLENECK---------------------\n",
    "#decoder = Dense(8, activation='relu')(encoder)\n",
    "decoder = Dense(16, activation='relu')(encoder)\n",
    "decoder = Dense(32, activation='relu')(decoder)\n",
    "decoder = Dense(128, activation='relu')(decoder)\n",
    "decoder = Dense(164, activation='relu')(decoder)\n",
    "decoder = Dense(adm1_codes_train.shape[1], activation='sigmoid')(decoder)\n",
    "\n",
    "autoencoder = Model(input_data, decoder)\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38c75d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 205)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 164)               33784     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               21120     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                96        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 164)               21156     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 205)               33825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,490\n",
      "Trainable params: 119,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17179213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "81/81 [==============================] - 2s 14ms/step - loss: 0.2499 - val_loss: 0.2497\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2495 - val_loss: 0.2493\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2491 - val_loss: 0.2489\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2488 - val_loss: 0.2486\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2484 - val_loss: 0.2482\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 0.2480 - val_loss: 0.2479\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2477 - val_loss: 0.2475\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2473 - val_loss: 0.2471\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2469 - val_loss: 0.2468\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2466 - val_loss: 0.2464\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2462 - val_loss: 0.2460\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2458 - val_loss: 0.2456\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2454 - val_loss: 0.2453\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2451 - val_loss: 0.2449\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2447 - val_loss: 0.2445\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2443 - val_loss: 0.2441\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2439 - val_loss: 0.2437\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2435 - val_loss: 0.2433\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2431 - val_loss: 0.2429\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2427 - val_loss: 0.2425\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2423 - val_loss: 0.2421\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2419 - val_loss: 0.2417\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2415 - val_loss: 0.2413\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.2410 - val_loss: 0.2408\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2406 - val_loss: 0.2404\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2402 - val_loss: 0.2400\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2397 - val_loss: 0.2395\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2393 - val_loss: 0.2391\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2388 - val_loss: 0.2386\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2384 - val_loss: 0.2381\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2379 - val_loss: 0.2376\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2374 - val_loss: 0.2372\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2369 - val_loss: 0.2367\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2364 - val_loss: 0.2362\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2359 - val_loss: 0.2356\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2354 - val_loss: 0.2351\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2348 - val_loss: 0.2345\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2343 - val_loss: 0.2340\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2337 - val_loss: 0.2334\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2331 - val_loss: 0.2328\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2325 - val_loss: 0.2322\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2319 - val_loss: 0.2316\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2313 - val_loss: 0.2309\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2306 - val_loss: 0.2302\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2299 - val_loss: 0.2295\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2292 - val_loss: 0.2288\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2285 - val_loss: 0.2281\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2277 - val_loss: 0.2273\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2269 - val_loss: 0.2265\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2261 - val_loss: 0.2256\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2252 - val_loss: 0.2248\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2243 - val_loss: 0.2238\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2234 - val_loss: 0.2229\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2224 - val_loss: 0.2219\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2214 - val_loss: 0.2208\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2203 - val_loss: 0.2197\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2191 - val_loss: 0.2185\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2179 - val_loss: 0.2173\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2166 - val_loss: 0.2159\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2153 - val_loss: 0.2145\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2138 - val_loss: 0.2130\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2122 - val_loss: 0.2114\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2106 - val_loss: 0.2097\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2088 - val_loss: 0.2079\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2069 - val_loss: 0.2059\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2048 - val_loss: 0.2037\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2026 - val_loss: 0.2014\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.2001 - val_loss: 0.1988\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1974 - val_loss: 0.1960\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1945 - val_loss: 0.1929\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1913 - val_loss: 0.1895\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1876 - val_loss: 0.1857\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1836 - val_loss: 0.1814\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1791 - val_loss: 0.1766\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1740 - val_loss: 0.1712\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1682 - val_loss: 0.1650\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1616 - val_loss: 0.1579\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1540 - val_loss: 0.1498\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1453 - val_loss: 0.1404\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1353 - val_loss: 0.1298\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1240 - val_loss: 0.1177\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.1113 - val_loss: 0.1044\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0975 - val_loss: 0.0901\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0830 - val_loss: 0.0756\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0686 - val_loss: 0.0615\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0552 - val_loss: 0.0488\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0433 - val_loss: 0.0380\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0335 - val_loss: 0.0293\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0259 - val_loss: 0.0227\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0202 - val_loss: 0.0179\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0133 - val_loss: 0.0121\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 88/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 1/200\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 2/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 3/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 4/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 5/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 6/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 7/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 9/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 12/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 13/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 15/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 17/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 19/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 20/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 21/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 22/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 23/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 24/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 25/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 26/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 27/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 28/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 29/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 30/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 31/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 32/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 33/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 35/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 36/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 37/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 38/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 39/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 40/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 41/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 42/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 43/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 44/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 45/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 46/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 47/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 49/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 50/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 51/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 52/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 53/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 54/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 55/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 56/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 57/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 58/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 59/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 60/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 61/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 62/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 63/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 64/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 65/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 66/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 67/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 68/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 69/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 70/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 71/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 72/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 73/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 74/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 75/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 76/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 77/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 78/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 79/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 80/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 81/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 82/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 83/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 84/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 85/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 86/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 87/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 89/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 90/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 91/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 92/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 93/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 94/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 95/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 96/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 97/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 98/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 99/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 100/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 101/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 102/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 104/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 105/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 106/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 107/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 108/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 109/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 110/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 111/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 112/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 113/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 114/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 115/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 116/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 117/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 118/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 119/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 120/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 121/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 122/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 123/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 124/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 125/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 126/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 127/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 128/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 129/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 130/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 131/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 132/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 133/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 134/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 135/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 136/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 137/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 138/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 139/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 140/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 141/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 142/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 143/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 144/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 145/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 146/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 147/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 148/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 149/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 150/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 151/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 152/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 153/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 154/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 155/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 156/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 157/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 158/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 159/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 160/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 161/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 162/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 163/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 164/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 165/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 166/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 167/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 168/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 169/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 170/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 171/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 172/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 173/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 174/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 175/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 176/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 177/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 178/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 179/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 180/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 181/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 182/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 183/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 184/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 185/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 186/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 187/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 188/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 189/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 190/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 191/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 192/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 193/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 197/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 199/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 200/200\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "#fit the autoencoder\n",
    "for i in range(0,5):\n",
    "    noise = np.random.normal(loc=0.0, scale=0.1, size=adm1_codes_train.shape)\n",
    "    adm1_codes_train_noisy = adm1_codes_train + noise\n",
    "    noise = np.random.normal(loc=0.0, scale=0.1, size=adm1_codes_test.shape)\n",
    "    adm1_codes_test_noisy = adm1_codes_test + noise\n",
    "    autoencoder.fit(adm1_codes_train_noisy, adm1_codes_train, epochs=200, batch_size=1000, shuffle=True, validation_data=(adm1_codes_test_noisy, adm1_codes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e88e3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use only encoder part to turn adm1 codes into separate attributes\n",
    "encoder_net = Model(input_data, encoder)\n",
    "\n",
    "X_train_encoded = encoder_net.predict(adm1_codes_train, batch_size=1)\n",
    "X_test_encoded = encoder_net.predict(adm1_codes_test, batch_size=1)\n",
    "adm1_codes_encoded = encoder_net.predict(adm1_codes, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b808e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100040, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying that there are 5 columns resulting from the autoencoder\n",
    "adm1_codes_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe46772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100040, 45)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "055a1763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234249</td>\n",
       "      <td>2.113737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.078864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.398172</td>\n",
       "      <td>2.291194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.344469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.275943</td>\n",
       "      <td>2.205956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.180590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.083962</td>\n",
       "      <td>1.906782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.769087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.302785</td>\n",
       "      <td>2.069894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.099730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.175822</td>\n",
       "      <td>2.007987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.903824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.336921</td>\n",
       "      <td>2.193148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.248803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.246624</td>\n",
       "      <td>2.087355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.035533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.187395</td>\n",
       "      <td>2.042254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.978177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.246624</td>\n",
       "      <td>2.087355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.035533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20008 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2    3         4\n",
       "0      0.0  1.234249  2.113737  0.0  3.078864\n",
       "1      0.0  1.398172  2.291194  0.0  3.344469\n",
       "2      0.0  1.275943  2.205956  0.0  3.180590\n",
       "3      0.0  1.083962  1.906782  0.0  2.769087\n",
       "4      0.0  1.302785  2.069894  0.0  3.099730\n",
       "...    ...       ...       ...  ...       ...\n",
       "20003  0.0  1.175822  2.007987  0.0  2.903824\n",
       "20004  0.0  1.336921  2.193148  0.0  3.248803\n",
       "20005  0.0  1.246624  2.087355  0.0  3.035533\n",
       "20006  0.0  1.187395  2.042254  0.0  2.978177\n",
       "20007  0.0  1.246624  2.087355  0.0  3.035533\n",
       "\n",
       "[20008 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have a look at the encoded adm1 levels\n",
    "pd.DataFrame(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b642cc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5310875649740104"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test how well the simple logistic regression model is doing with the encoded variables\n",
    "lg.fit(X_train_encoded, adm1_codes_y_train)\n",
    "lg.score(X_test_encoded,adm1_codes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e11ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create another confusion matrix to ensure that not only the majority class is predicted\n",
    "adm1_codes_y_pred_new = lg.predict(X_test_encoded)\n",
    "cf_matrix = confusion_matrix(adm1_codes_y_pred_new, adm1_codes_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66feaaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8665, 2041],\n",
       "       [7341, 1961]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1767ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(cf_matrix, annot = True,  cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7daf9921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8115753698520591\n",
      "0.8109006397441023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Shadow\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shadow\\anaconda3\\envs\\tf-keras-gpu-2\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#join the new ADM1 compressed dimensions withe the one-hot-encoded ones and retrain the logistic regression\n",
    "df_all_adm1 = pd.concat([adm1_codes, pd.DataFrame(adm1_codes_encoded)], axis = 1)\n",
    "df_all_adm1\n",
    "df_all_adm1_train, df_all_adm1_test, df_all_adm1_y_train, df_all_adm1_y_test = train_test_split(df_all_adm1, adm1_codes_y, test_size=0.2, random_state=42)\n",
    "lg.fit(df_all_adm1_train, df_all_adm1_y_train)\n",
    "print(lg.score(df_all_adm1_test , df_all_adm1_y_test))\n",
    "print(lg.score(df_all_adm1_train , df_all_adm1_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a886918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the newly encoded adm1 codes to the dataframe\n",
    "df_complete = df_complete.reset_index(drop=True)\n",
    "df_complete = df_complete.join(pd.DataFrame(adm1_codes_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4677125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2325e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all non-numeric columns except for the date field \n",
    "df_complete.drop(columns = [\"ActionGeo_ADM1Code\", \"Country Code\", \"country\", \"iso_code\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete3 = df_complete.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba48233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date dimension into numeric field \n",
    "df_complete3['InsertedDate'] = pd.to_datetime(df_complete3['MonthYear'], format='%Y%m')\n",
    "df_complete3['InsertedDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00771bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##experiment with date feature\n",
    "list_1 = list(df_complete3['InsertedDate'])\n",
    "minimum_list1 = min(list_1)\n",
    "\n",
    "# Get the list with seconds since earliest event\n",
    "list_2 = [(i - minimum_list1).total_seconds() for i in list_1]\n",
    "# Normalize data so it lies between 0 and 1\n",
    "#list_3 = [i/max(list_2) for i in list_2]\n",
    "#print(date_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e002f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete3['MonthYear_New'] = list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cade5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete3.drop(columns =['InsertedDate', 'year', 'MonthYear'], inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda6a79",
   "metadata": {},
   "source": [
    "### 5) Checking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e8f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating correlations with all predictors to the target variable\n",
    "df_corr = df_complete3.corrwith(df_complete3['number of conflicts'])\n",
    "df_corr = df_corr.reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9a111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values \n",
    "na_corr = list(df_corr[df_corr[0].isna() == True]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165abfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we check maximum and minimum correlations, we exclude the target variable itself, which would have a perfect correlation of 1\n",
    "df_corr = df_corr[df_corr['index'] != 'number of conflicts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the maximum correlation\n",
    "df_corr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20731c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the minimzm correlation\n",
    "df_corr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dataframe for the next notebook\n",
    "df_complete3.to_pickle(path = \"df_complete3_v3.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
